# ğŸŒŒ Classification dâ€™Ã©vÃ©nements astrophysiques avec l'apprentissage automatique

Ce dÃ©pÃ´t contient un projet de classification d'Ã©vÃ©nements captÃ©s par un tÃ©lescope Ã  rayons gamma Ã  l'aide de techniques d'apprentissage automatique, allant du prÃ©traitement Ã  l'entraÃ®nement de rÃ©seaux de neurones avec PyTorch.

---

## ğŸ“‚ Contenu

### 1. `la_visualisation_preprocessing_machine_learning.ipynb`
Ce notebook inclut :
- ğŸ“¥ Chargement des donnÃ©es
- ğŸ“Š Visualisation : distribution des classes, corrÃ©lations
- ğŸ§¹ PrÃ©traitement : normalisation, suppression des valeurs aberrantes, correction des valeurs manquantes avec Yo-Jonson, Ã©quilibrage des classes avec SMOTE
- ğŸ¤– ModÃ¨les de machine learning traditionnels (RandomForest, SVM, etc.)

### 2. `le_reseaux_neurones_pytorch.ipynb`
Ce notebook inclut :
- ğŸ”„ PrÃ©paration des donnÃ©es pour PyTorch
- ğŸ§  DÃ©finition d'un rÃ©seau de neurones entiÃ¨rement connectÃ©
- ğŸ‹ï¸ EntraÃ®nement et validation du modÃ¨le
- ğŸ“ˆ Ã‰valuation : courbes de perte, matrice de confusion, scores de performance

---

## ğŸ“Š RÃ©sultats des ModÃ¨les

### ğŸ”¬ RÃ©seaux de Neurones (PyTorch)

| MÃ©thode                                   | Accuracy | Precision | Recall   | F1 Score |
|-------------------------------------------|----------|-----------|----------|----------|
| RÃ©seaux de Neurones (Adam Optimizer)      | 0.877965 | 0.878371  | 0.877965 | 0.867373 |
| RÃ©seaux de Neurones (SGD Optimizer)       | 0.864991 | 0.866386  | 0.864991 | 0.864797 |
| RÃ©seaux de Neurones (RandomizedSearchCV)  | 0.867423 | 0.867672  | 0.867423 | 0.867373 |
| RÃ©seaux de Neurones (Grid Search)         | 0.877357 | 0.877608  | 0.877357 | 0.877311 |

### âš™ï¸ ModÃ¨les de Machine Learning Traditionnels

| ModÃ¨le                      | Accuracy | Precision | Recall   | F1 Score |
|----------------------------|----------|-----------|----------|----------|
| Logistic Regression        | 0.803966 | 0.811570  | 0.791759 | 0.801459 |
| Decision Tree              | 0.841470 | 0.879157  | 0.790866 | 0.832128 |
| Extreme Gradient Boosting  | 0.891097 | 0.908288  | 0.870011 | 0.888623 |
| Gradient Boosting          | 0.819900 | 0.817094  | 0.824439 | 0.820676 |
| Random Forest              | 0.896895 | 0.906564  | 0.885013 | 0.895418 |
| Support Vector Machine     | 0.869121 | 0.909634  | 0.819655 | 0.862262 |
| Gaussian Naive Bayes       | 0.675446 | 0.722498  | 0.674546 | 0.656012 |

---
## ğŸ³ Conteneurisation avec Docker

Pour assurer la portabilitÃ©, la facilitÃ© de dÃ©ploiement et la reproductibilitÃ© de lâ€™environnement, ce projet est conteneurisÃ© avec **Docker**. La conteneurisation permet dâ€™emballer toutes les dÃ©pendances, configurations et le code dans une image lÃ©gÃ¨re et isolÃ©e, garantissant que lâ€™application fonctionne de maniÃ¨re identique quel que soit lâ€™environnement.


### Exemple de fichier `requirements.txt`

```
flask==3.1.0
scikit-learn==1.6.1
xgboost==2.1.4
joblib==1.4.2
numpy==2.0.1
pandas==2.2.3
torch==2.5.1
matplotlib==3.8.4
seaborn==0.12.2
```

---

## ğŸ³ Conteneurisation avec Docker

### ğŸ”§ Construction de lâ€™image

```bash
docker build -t astrophysics-classification .
```

### ğŸš€ Lancement du conteneur

```bash
docker run -p 8888:8888 -v $(pwd):/app astrophysics-classification
```

### ğŸ“¦ Exemple de Dockerfile

```dockerfile
# Utilisation d'une image Python officielle slim
FROM python:3.12.4-slim

# Variables d'environnement
ENV PYTHONUNBUFFERED=1 \
    PIP_DEFAULT_TIMEOUT=100 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# RÃ©pertoire de travail
WORKDIR /app

# Copier uniquement le fichier des dÃ©pendances
COPY temp_requirements.txt .

# Installer les dÃ©pendances
RUN pip install --no-cache-dir --retries 5 -r temp_requirements.txt

# Copier le reste des fichiers de l'application
COPY . .

# Exposer le port (ex : 5000 pour Flask)
EXPOSE 5000

# Commande de dÃ©marrage
CMD ["python", "app.py"]
```

---

## ğŸ§¾ Conclusion

Les rÃ©sultats expÃ©rimentaux montrent que les modÃ¨les dâ€™ensemble comme **Random Forest** et **XGBoost** surpassent la majoritÃ© des autres approches en termes de performance globale. **Random Forest**, en particulier, offre un excellent compromis entre prÃ©cision, rappel et f1-score, ce qui en fait un choix pertinent pour les tÃ¢ches de classification.

Concernant les rÃ©seaux de neurones, les performances sont Ã©galement solides, surtout avec des optimisations comme **Grid Search** ou lâ€™**optimiseur Adam**. Cependant, ils nÃ©cessitent un temps d'entraÃ®nement plus long et une configuration plus fine des hyperparamÃ¨tres.

**En rÃ©sumÃ©** :

âœ… *Random Forest* est le modÃ¨le le plus robuste et performant dans ce contexte.  
âš™ï¸ *XGBoost* est trÃ¨s compÃ©titif, notamment pour maximiser les performances.  
ğŸ§  *Les rÃ©seaux de neurones* sont prometteurs, surtout pour des architectures plus complexes ou lâ€™intÃ©gration de donnÃ©es non structurÃ©es Ã  lâ€™avenir.

Ce travail met en Ã©vidence l'importance du **choix du modÃ¨le** en fonction des **ressources disponibles**, du **besoin en interprÃ©tabilitÃ©**, de la **performance** et de la **scalabilitÃ©**.

---
